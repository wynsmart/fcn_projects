<PERSONAL INFO>
name: Fan Yang
nuid: 00-179-7661
email: yang.fan7@husky.neu.edu

name: Samkeet Shah
nuid: 001258979
email: shah.sam@husky.neu.edu


<HIGH-LEVEL APPROACH>
- ./webcrawler command calls the main.py with the given arguments.
- main.py calls utils.py to initialize the logger and parameter parser for the
  given application
- main.py initializes an Object of MyCrawler passing the root path of the fakebook.com
  MyCrawler creates a MyPaw object to login to the website using the given
  arguments (username and password) using a HTTP POST request.
- Further it creates a HTTP wrapper to send and receive custom HTTP responses using
  HTTP GET requests.
- The crawler starts crawling from the root URL after successful login and
  performs a BFS in multi-threaded mode to scan for <a href="/..."> tags and
  <h2 class = "secret_flags"> tags using a regex.
- the crawler maintains a 'seen' set to store the list of URLs seen before, then
  pops one from the queue and adds the links found on that page to unvisited list.
- It stores all secret_flags found in a secret_flags dictionary and prints all
  flags after crawling all pages.


<CHALLENGES>
1. Handle chunked http response
2. TCP checksum algorithm
3. send/recv socket (addr_family, type, protocol)
4. problem when buffer_size of socket.recv() is smaller than data size, checksum fails
5. congestion window and socket timeout

<TESTING>
1. Testing without multi-threading. (took > 20 mins to crawl)
2. Testing with multi-threading (takes upto 1.5 mins)
3. Handling errors due to fewer arguments.


<WORK LOAD>
Fan Yang:
- Parsed arguments;
- Handled socket connection and requests;
- Reverse engineered login page to implement Fakebook login;
- Provided 'fetch' api to get data of given path;
- [Files] utils.py, conns.py

Samkeet Shah:
- Implemented basic BFS algorithm with 'fetch' api;
- Improved BFS with multi-threading to speed up;
- Assembled the main entry function
- [Files] main.py, crawler.py
